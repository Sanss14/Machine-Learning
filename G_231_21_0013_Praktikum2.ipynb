{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFmJPzU9fHEJRzIvAkJzLV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanss14/Machine-Learning/blob/main/G_231_21_0013_Praktikum2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengimpor pustaka yang diperlukan dan mengunggah file ke lingkungan Colab"
      ],
      "metadata": {
        "id": "9FzR8Ch_2UxW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "_UpLCr8svFxF",
        "outputId": "29f4d52f-5362-4536-d6d5-27c7ce155297"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28c424d0-0ef7-481a-b740-9ddd17a9410d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28c424d0-0ef7-481a-b740-9ddd17a9410d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.csv to train (1).csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Memuat sebuah dataset dari file CSV ke dalam sebuah DataFrame Pandas"
      ],
      "metadata": {
        "id": "Mo_GRTnf2bB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "YxBTObimwAVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengklasifikasikan kolom-kolom dalam DataFrame Pandas ke dalam dua kategori berdasarkan tipe datanya: kategori kategorikal (categorical) dan kategori numerik (numerical)"
      ],
      "metadata": {
        "id": "-xyDoG_O23kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical columns\n",
        "cat_col = [col for col in df.columns if df [col].dtype == 'object']\n",
        "print('Categorical columns :', cat_col)\n",
        "# Numerical columns\n",
        "num_col = [col for col in df.columns if df [col].dtype != 'object']\n",
        "print('Numerical columns :', num_col)"
      ],
      "metadata": {
        "id": "aT_vg9RMzvMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menganalisis dan memahami data dalam sebuah DataFrame Pandas"
      ],
      "metadata": {
        "id": "HgFQ18lf4ZX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated()\n",
        "df.info()\n",
        "df.describe()\n",
        "df[cat_col].nunique()"
      ],
      "metadata": {
        "id": "vXuH31nLxiDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengambil 50 nilai unik pertama dari kolom 'Ticket' dalam DataFrame Pandas"
      ],
      "metadata": {
        "id": "0SCxOB6S4ikQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Ticket'].unique()[:50]"
      ],
      "metadata": {
        "id": "Hn9Muxj0x1AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Pengolahan DataFrame menggunakan pustaka Pandas"
      ],
      "metadata": {
        "id": "ibXeyuFj4lhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.drop(columns=['Name','Ticket'])\n",
        "df1.shape"
      ],
      "metadata": {
        "id": "hyYu_w_AyHrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menghitung persentase data yang hilang (missing data) dalam setiap kolom (variabel) dari DataFrame df1"
      ],
      "metadata": {
        "id": "4OdXBhHY4ukS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "round((df1.isnull().sum()/df1.shape[0])*100,2)"
      ],
      "metadata": {
        "id": "_1yDwA-VzCxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melakukan beberapa operasi pada sebuah DataFrame"
      ],
      "metadata": {
        "id": "fHd4ZoYI49d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1.drop(columns='Cabin')\n",
        "df2.dropna(subset=['Embarked'], axis=0, inplace=True)\n",
        "df2.shape"
      ],
      "metadata": {
        "id": "AxcWwaEd2eOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teknik imputasi rata-rata untuk mengatasi nilai-nilai yang hilang dalam kolom Age dalam DataFrame Pandas df2, dan kemudian memeriksa apakah masih ada nilai yang hilang"
      ],
      "metadata": {
        "id": "uJ8IpNKn5dwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean imputation\n",
        "df3 = df2.fillna(df2.Age.mean())\n",
        "# Let's check the null values again\n",
        "df3.isnull().sum()"
      ],
      "metadata": {
        "id": "L9inVMs0VyJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menghitung statistik ringkasan (summary statistics) dari kolom 'Age' dalam DataFrame, menghitung batas bawah (lower bound) dan batas atas (upper bound) sebagai bagian dari analisis outlier, dan kemudian menghapus outlier dari DataFrame"
      ],
      "metadata": {
        "id": "Sw2vrSji6Dm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate summary statistics\n",
        "mean = df3['Age'].mean()\n",
        "std = df3['Age'].std()\n",
        "\n",
        "# calculate the lower and upper bounds\n",
        "lower_bound = mean - std*2\n",
        "upper_bound = mean + std*2\n",
        "\n",
        "print('Lower Bound :',lower_bound)\n",
        "print('Upper Bound :',upper_bound)\n",
        "\n",
        "# Drop the outliers\n",
        "df4 = df3[(df3['Age'] >= lower_bound)\n",
        "                & (df3['Age'] <= upper_bound)]"
      ],
      "metadata": {
        "id": "fFeDCpMIV1RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat sebuah box plot (Diagram Kotak) menggunakan pustaka Matplotlib"
      ],
      "metadata": {
        "id": "ss0ENjSz6N38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.boxplot(df3['Age'], vert=False)\n",
        "plt.ylabel('Variable')\n",
        "plt.xlabel('Age')\n",
        "plt.title('Box Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hb5tG6_kV4pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mempersiapkan data untuk pembuatan model prediksi"
      ],
      "metadata": {
        "id": "7iV3A4Mq6P2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df3[['Pclass','Sex','Age','Sibsp','Parch','Fare','Embarked']]\n",
        "Y = df3['Survived']"
      ],
      "metadata": {
        "id": "WIWuj1b_V8I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melakukan penskalaan fitur menggunakan MinMaxScaler dari pustaka Scikit-Learn (sklearn)"
      ],
      "metadata": {
        "id": "aLwmMEVV6etb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# initialising the MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Numerical columns\n",
        "num_col_ = [col for col in X.columns if X[col].dtype != 'object']\n",
        "x1 = X\n",
        "# learning the statistical parameters for each of the data and transforming\n",
        "x1[num_col_] = scaler.fit_transform(x1[num_col_])\n",
        "x1.head()"
      ],
      "metadata": {
        "id": "W2UBmnLFWFzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengimpor beberapa modul dan pustaka yang diperlukan untuk melakukan analisis data dan pemodelan"
      ],
      "metadata": {
        "id": "hQnYzjlT6sur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary modules\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "metadata": {
        "id": "plVblKFPwFzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Memuat (load) dataset dari file CSV dengan nama 'creditcard.csv' ke dalam sebuah DataFrame Pandas dan kemudian mencetak informasi mengenai kolom-kolom dalam DataFrame tersebut"
      ],
      "metadata": {
        "id": "px3D8_hL6wDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data set\n",
        "data = pd.read_csv('creditcard.csv')\n",
        "\n",
        "# print info about columns in the dataframe\n",
        "print(data.info())"
      ],
      "metadata": {
        "id": "B6xMzKkiwLiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memproses data yang berkaitan dengan deteksi kecurangan (fraud detection) dalam dataset transaksi finansial"
      ],
      "metadata": {
        "id": "JYrxfNfc7BHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalise the amount column\n",
        "data['normAmount'] = StandardScaler().fit_transform(np.array(data['Amount']).reshape(-1, 1))\n",
        "\n",
        "# drop Time and Amount columns as they are not relevant for prediction purpose\n",
        "data = data.drop(['Time', 'Amount'], axis = 1)\n",
        "\n",
        "# as you can see there are 492 fraud transactions\n",
        "data['Class'].value_counts()"
      ],
      "metadata": {
        "id": "3gxukk1pwN8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membagi dataset menjadi dua set, yaitu set pelatihan (train) dan set pengujian (test) menggunakan modul train_test_split dari pustaka Scikit-Learn (sklearn)"
      ],
      "metadata": {
        "id": "9KUBJVi97OLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split into 70:30 ration\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
        "\n",
        "# describes info about train and test set\n",
        "print(\"Number transactions X_train dataset :\", X_train.shape)\n",
        "print(\"Number transactions y_train dataset :\", y_train.shape)\n",
        "print(\"Number transactions X_test dataset :\", X_test.shape)\n",
        "print(\"Number transactions y_test dataset :\", y_test.shape)"
      ],
      "metadata": {
        "id": "LUQeJ78LwPye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melakukan tindakan dengan penggunaan algoritme Logistic Regression dalam pembuatan dan evaluasi model klasifikasi"
      ],
      "metadata": {
        "id": "4S7qHVkW7WKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression object\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# train the model on train set\n",
        "lr.fit(X_train, y_train.ravel())\n",
        "\n",
        "predictions = lr.predict(X_test)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "ptHPCBkFwRgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengatasi masalah ketidakseimbangan kelas (class imbalance) dalam masalah klasifikasi"
      ],
      "metadata": {
        "id": "KEY9Uk1S7ofk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
        "\n",
        "# import SMOTE module from imblearn library\n",
        "# pip install imblearn (if you don't have imblearn in your system)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 2)\n",
        "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of tabel '1': {}\".format(sum(y_train_res == 1)))\n",
        "print(\"After OverSampling, counts of tabel '0': {}\".format(sum(y_train_res == 0)))"
      ],
      "metadata": {
        "id": "4UDALmKlwTK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membangun dan mengevaluasi sebuah model klasifikasi"
      ],
      "metadata": {
        "id": "WZMdGl4d7vuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression object\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# train the model on train set\n",
        "lr.fit(X_train, y_train.ravel())\n",
        "\n",
        "predictions = lr.predict(X_test)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "ji-cNuTcwVDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengatasi masalah ketidakseimbangan kelas (class imbalance) dalam sebuah dataset"
      ],
      "metadata": {
        "id": "AJStWiAD73Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
        "\n",
        "# import SMOTE module from imblearn library\n",
        "# pip install imblearn (if you don't have imblearn in your system)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 2)\n",
        "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of tabel '1': {}\".format(sum(y_train_res == 1)))\n",
        "print(\"After OverSampling, counts of tabel '0': {}\".format(sum(y_train_res == 0)))"
      ],
      "metadata": {
        "id": "Z6S_HUd0wW98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melakukan analisis klasifikasi menggunakan model Regresi Logistik (Logistic Regression) pada data yang telah dibagi menjadi set pelatihan (training set) dan set pengujian (testing set)"
      ],
      "metadata": {
        "id": "-xMEe_K37-yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr1 = LogisticRegression()\n",
        "lr1.fit(X_train, y_train_res.ravel())\n",
        "predictions = lr1.predict(X_test)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "i7b-Q440wZRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melakukan undersampling pada dataset yang tidak seimbang (imbalance dataset) untuk mengatasi ketidakseimbangan kelas"
      ],
      "metadata": {
        "id": "vzM8EJnF8HCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before Undersampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before Undersampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
        "\n",
        "# apply near miss\n",
        "from imblearn.under_sampling import NearMiss\n",
        "nr = NearMiss()\n",
        "\n",
        "X_train_miss, y_train_miss = nr.fit_sample(X_train.ravel())\n",
        "\n",
        "print('After Undersampling, the shape of train_X: {}'.format(X_train_miss.shape))\n",
        "print('After Undersampling, the shape of train_y: {} \\n'.format(y_train_miss.shape))\n",
        "\n",
        "print(\"After Undersampling, counts of tabel '1': {}\".format(sum(y_train_miss == 1)))\n",
        "print(\"After Undersampling, counts of tabel '0': {}\".format(sum(y_train_miss == 0)))"
      ],
      "metadata": {
        "id": "3BkafPaIwbTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melatih sebuah model klasifikasi logistik (Logistic Regression) pada dataset pelatihan (train set), melakukan prediksi pada dataset pengujian (test set), dan mencetak laporan klasifikasi (classification report)"
      ],
      "metadata": {
        "id": "v0bkvVit8OXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model on train set\n",
        "lr2 = LogisticRegression()\n",
        "lr2.fit(X_train_miss, y_train_miss.ravel())\n",
        "predictions = lr2.predict(X_test)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "K3nhrZKXwc5r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}